%!TEX root = ../main.tex

\section{Introduction}
\label{s:intro}

\xxx{Sketch of arguments}

While exploring data, its natural to come across surprising or unexpected data.
For example, visual data analysis explores the current state of the database and users may be surprised by outliers in a visualization.
Similarly, enterprise customers (e.g., billing) may find outliers in their monthly bills and be surprised by the amount they are asked to pay.

When presented with these surprises, users want to better understand the reasons behind the anomalies.
A recent wave of research focuses on deriving predicate-based explanations for outliers for statistical aggregation queries.
For example, if the user wants to understand why the total sales in the past few months have gone up, these systems can general explanations such as ``most related to customers in California between the ages of 12 to 18.''
However, these approaches simply generate predicates that describe {\it current state} of the database, and do not resolve {\it how} the anomalous data came to be.

Specifically, the user may also be interested to understand which past database modification was responsible for these explanations.
Describe why this makes sense to want.  In this form of the problem, we are interested in historical database queries whose modifications, when propogated to the current database state, 
The goal is to provide diagnostic tools that can peer into past transactions.


In this paper, we approach anomaly explanation from the persepctive of the query log and seek to
both {\it identify}  historical database modification queries that most likely caused user complaints 
in the current state of the database, and suggest replacement queries that will resolve these complaints.
We call this problem the {\it Query-based Complaint-Satisfaction Problem}.

Given a database query log and a set of {\it complaints} (e.g., tuple 1's attribute B should be 20\% lower) about records in the current state of the database,
we seek to identify the subset of queries in the log that, by modifying their parameters and propogating the new effects of the queries, 
will best resolve the complaints.  

One way to solve this problem is to try modifying the most recent query until it fixes the complaints.  
If not, then try the second most recent query.  
The problem with this approach is the number of possible modifications is unbounded.

Our contributions include

\begin{enumerate}
\item Developing and formalizing the problem of Query-oriented explanation in contrast to data-oriented explanation
\item Prove that the general problem is impossible.
\item Designing alogirthems to solve the problem for complete complaint sets
\item Extending the algorithms to support incomplete complaint sets
\item Extending to support multiple queries
\end{enumerate}

%%%%%%%%%%%%%%% Clean up.... %%%%%%%%%%%%%%

Sometimes, data starts clean but gets tainted due to erroneous
updates. Errors in queries need to be handled differently than errors
in data, since they pose their own unique challenges:

\begin{description}[leftmargin=5mm, topsep=0mm, itemsep=0mm]
    \item[Systemic errors.] The errors created by bad queries are
    systemic. The link between the resulting errors is the query
    that created them; cleaning techniques should leverage this
    connection to diagnose and fix the problem.
    
    \item[Large impact.] Erroneous queries cause errors in a large
    scale. This means that the potential impact of the error is high,
    which has been manifested in several real-world
    cases.%~\cite{Yates10, Grady13, sakalerrors}
    
    \item[Obscurity.] Detection of the resulting errors often leads to
    partial fixes that further complicate the eventual diagnosis and
    resolution of the problem. For example, a transaction implementing
    a change in the state tax law updated tax rates using the wrong
    rate, affecting a large number of consumers. This causes a large
    number of complaints to a call center, but each customer agent
    usually fixes each problem individually, which ends up obscuring
    the source of the problem.
    
    \item[Feasibility.] Query errors can easily remain undetected
    for a significant amount of time, which, in turn, makes correcting
    the mistake a huge undertaking. Essentially, a very old
    transaction would need to be rolled back, which poses obvious
    hurdles.
\end{description}

The goal of this paper is to design effective query
diagnosis techniques and identify possible fixes for query errors. We
model the problem assuming a log of update workloads over a database,
and a set of complaints that identify errors in the final database
state. We organize our contributions as follows:

\begin{description}[leftmargin=5mm, topsep=0mm, itemsep=0mm]        
    \item[Diagnosis with complete information:] We will first tackle the
    problem assuming that the complaint set is complete, i.e., all errors in
    the final data instance have been labeled. In Section~\ref{??}, we will
    present algorithms that identify the query responsible for all errors in
    the complaint set.
    
    \item[Diagnosis with incomplete information:] We will extend our
    algorithms to account for incomplete information, which is a more
    realistic scenario: some complaints have identified errors in the
    final data instance, but the set is not complete (Section~\ref{??}).
    
    \item[Deriving fixes:] We will derive potential fixes to correct
    the errors.
    
    \item[Evaluation:]...
\end{description}



\section{Use Case}

\section{Architecture}









